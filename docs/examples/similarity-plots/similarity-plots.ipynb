{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing a threshold\n",
    "\n",
    "Imagine that you are a data analyst. You are given two sets of CLKs (possibly generated using clkhash) and it is your task to use anonlink produce a linkage.\n",
    "\n",
    "Luckily for you, anonlink takes care of most of this process. However, it needs to be given one parameter: the _threshold_. The threshold is a number that defines how similar two CLKs must be in order to be accepted as a match. In this example, we are using the Sørensen–Dice coefficient as the similarity metric, so the threshold is a number between 0 and 1.\n",
    "\n",
    "Choosing a threshold can be nontrivial, but anonlink has some tools to help you with this selection. Let's explore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "\n",
    "import base64\n",
    "import json\n",
    "\n",
    "import bitarray\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import anonlink\n",
    "\n",
    "\n",
    "def to_bitarray(bytes_):\n",
    "    ba = bitarray.bitarray()\n",
    "    ba.frombytes(bytes_)\n",
    "    return ba\n",
    "\n",
    "\n",
    "def load_clks(path):\n",
    "    with open(path) as f:\n",
    "        json_obj = json.load(f)['clks']\n",
    "    return tuple(map(to_bitarray, map(base64.b64decode, json_obj)))\n",
    "\n",
    "\n",
    "clks1 = load_clks('clks-1.json')\n",
    "clks2 = load_clks('clks-2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing similarities\n",
    "We are going to produce a few plots that will give us hints to the location of the threshold. These plots use the distribution of the similarity scores. This means that before we can make them, we need to compute some similarities.\n",
    "\n",
    "As a complication, to compute similarity scores, we need to input a threshold. _This_ threshold is not used for linkage—it is merely a cutoff value for our plots. Higher thresholds save processing time, but may produce incomplete graphs. For plotting purposes, a threshold value of 0 is safe, as long as you don't mind waiting a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTTING_THRESHOLD = 0\n",
    "\n",
    "all_candidate_pairs = anonlink.candidate_generation.find_candidate_pairs(\n",
    "        [clks1, clks2],\n",
    "        anonlink.similarities.dice_coefficient,\n",
    "        PLOTTING_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of similarities\n",
    "Let's plot a histagram of all the similarity scores! We'll use a log scale to deal with differences in order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarities_hist(candidate_pairs, bins=100):\n",
    "    \"\"\"Plot a histogram of the similarity scores in candidate pairs.\n",
    "\n",
    "    :param candidate_pairs: The candidate pairs.\n",
    "    :param bins: An integer determining the number of bins to use.\n",
    "        Default 100.\n",
    "    \"\"\"\n",
    "    counts, bin_boundaries = anonlink.stats.similarities_hist(candidate_pairs, bins)\n",
    "    plt.hist(bin_boundaries[:-1], bins=bin_boundaries, weights=counts)\n",
    "    plt.yscale('symlog')  # Log scale, but lets some values be 0\n",
    "    plt.title('Histogram of similarities')\n",
    "    plt.xlabel('Similarity')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "\n",
    "plot_similarities_hist(all_candidate_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see two populations. A big population of non-matching pairs with similarities <0.8 and a much smaller population of matching pairs with similarities >0.8.\n",
    "\n",
    "The large separation between those population is a sign that our data is reasonably clean and our encoding schema is doing a good job. The populations are not separated as cleanly in more difficult problems.\n",
    "\n",
    "Generally, the optimal threshold will be at the bottom of the trough between the two distributions.\n",
    "\n",
    "## Cumulative matches by threshold\n",
    "We can also plot the number of matches we would get by setting a particular threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumul_number_matches_vs_threshold(candidate_pairs, steps=100):\n",
    "    \"\"\"Plot the number of matches for each threshold.\n",
    "\n",
    "    We use the 2-party greedy solver to calculate the number of matches\n",
    "    that would be returned if the candidate_pairs were found using a\n",
    "    particular threshold. This function requires only a single pass of\n",
    "    the data, so it is faster than simply running the greedy solver\n",
    "    multiple times.\n",
    "\n",
    "    :param candidate_pairs: The candidate pairs.\n",
    "    :param steps: An integer determining the number of threshold steps\n",
    "        to use. Default 100.\n",
    "    \"\"\"\n",
    "    num_matches, thresholds = anonlink.stats.cumul_number_matches_vs_threshold(\n",
    "        candidate_pairs, steps)\n",
    "    plt.plot(thresholds, num_matches)\n",
    "    plt.title('Number of matches by threshold')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Number of matches')\n",
    "\n",
    "    \n",
    "plot_cumul_number_matches_vs_threshold(all_candidate_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the curve levels off around threshold of 0.8.\n",
    "\n",
    "The set of all possible pairs can be split into (1) a set of matches that may or may not be accepted (depending on the threshold) and (2) a much bigger set of pairs that will never be accepted by the greedy solver. The smaller set of possible matches has two well-separated subpopulations, and 0.8 appears to be right in-between. This makes 0.8 a good threshold.\n",
    "\n",
    "In less clean data, there might not be a clearly visible 'saddle point'.\n",
    "\n",
    "## Possible matches vs definite nonmatches ratio by threshold\n",
    "Finally, we can split the similarities into many buckets by threshold, and plot the ratio of possible matches against definite nonmatches by threshold. Definite nonmatches are pairs that will never be accepted by the greedy solver, whereas possible matches are ones that may or may not be accepted, depending on the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matches_nonmatches_ratio_hist(candidate_pairs, bins=100):\n",
    "    \"\"\"Plot the ratio of possible matches and definite nonmatches.\n",
    "\n",
    "    We use the greedy solver to split the candidate pairs into possible\n",
    "    matches and definite nonmatches. A possible match may or may not be\n",
    "    accepted as a pair depending on the threshold chosen. A definite\n",
    "    nonmatch will never be accepted, since one record in this pair has\n",
    "    a more promising match with another record. We then plot the ratio\n",
    "    of possible matches and definite nonmatches.\n",
    "\n",
    "    :param candidate_pairs: The candidate pairs.\n",
    "    :param bins: An integer determining the number of bins to use.\n",
    "        Default 100.\n",
    "    \"\"\"\n",
    "    matches_num, nonmatches_num, bin_boundaries = anonlink.stats.matches_nonmatches_hist(\n",
    "        candidate_pairs, bins)\n",
    "    all_num = matches_num + nonmatches_num\n",
    "\n",
    "    nonmatches_ratio = [nn * 100 / an if an else 0 for nn, an in zip(nonmatches_num, all_num)]\n",
    "    matches_ratio = [mn * 100 / an if an else 0 for mn, an in zip(matches_num, all_num)]\n",
    "    width = (bin_boundaries[-1] - bin_boundaries[0]) / (bin_boundaries.shape[0] - 1)\n",
    "\n",
    "    plt.bar(bin_boundaries[:-1], matches_ratio,\n",
    "            width=width, align='edge', label='Possible matches')\n",
    "    plt.bar(bin_boundaries[:-1], nonmatches_ratio,\n",
    "            width=width, bottom=matches_ratio, align='edge', label='Definite nonmatches')\n",
    "    plt.legend()\n",
    "    plt.title('Proportion of possible matches by similarity')\n",
    "    plt.xlabel('Similarity')\n",
    "    plt.ylabel('Proportion (%)')\n",
    "\n",
    "    \n",
    "plot_matches_nonmatches_ratio_hist(all_candidate_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that all matches with a threshold of around 0.8 or more are accepted. This reinforces our previous beliefs that a good threshold is around 0.8.\n",
    "\n",
    "## Deciding on a threshold\n",
    "The above plots let us decide on a threshold. It will be around 0.8. Let's pick 0.81, since that's where the trough in the first plot lies.\n",
    "\n",
    "## Results\n",
    "Using the plots above, an analyst might choose a threshold of 0.81. Let's perform this linkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = .81\n",
    "\n",
    "results_candidate_pairs = anonlink.candidate_generation.find_candidate_pairs(\n",
    "        [clks1, clks2],\n",
    "        anonlink.similarities.dice_coefficient,\n",
    "        THRESHOLD)\n",
    "solution = anonlink.solving.greedy_solve(results_candidate_pairs)\n",
    "\n",
    "found_pairs = {(i, j) for (_, i), (_, j) in map(sorted, solution)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can cheat a little since we actually have the ground truth. (Normally having the ground truth would defeat the point of this linkage!) Let's compute the actual accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ground-truth.json') as f:\n",
    "    true_pairs = set(map(tuple, json.load(f)))\n",
    "    \n",
    "true_positives = len(found_pairs & true_pairs)\n",
    "false_positives = len(found_pairs) - true_positives\n",
    "false_negatives = len(true_pairs) - true_positives\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * true_positives / (2 * true_positives + false_negatives + false_positives)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 score: {f1_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An F1 score of .99 is very good. We might be able to improve upon it by adding another significant figure to our threshold (of course, finding it would require more fine-grained plots).\n",
    "\n",
    "Small deviations on this threshold would help us fine-tune the balance between precision and recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anonlink-venv",
   "language": "python",
   "name": "anonlink-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
